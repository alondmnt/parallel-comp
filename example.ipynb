{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARASCHUT notebook\n",
    "\n",
    "we'll go through a small-scale example of `parachut` tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "example/job_queue.db\nexample/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import paraschut as psu\n",
    "print(psu.config.QFile)\n",
    "print(psu.config.JobDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate a job\n",
    "\n",
    "we'll start from the default template and update it with data relevant to our example. note that these functions may be run offline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'BatchID': 20210220122655,\n",
       " 'JobIndex': 0,\n",
       " 'priority': 1,\n",
       " 'name': ['paraschut example'],\n",
       " 'data_type': 'foo',\n",
       " 'data': None,\n",
       " 'script': 'python example/job.py {BatchID} {JobIndex}',\n",
       " 'queue': 'tamir-nano4',\n",
       " 'resources': {'mem': '1gb',\n",
       "  'pmem': '1gb',\n",
       "  'vmem': '3gb',\n",
       "  'pvmem': '3gb',\n",
       "  'cput': '04:59:00'},\n",
       " 'state': 'init',\n",
       " 'CodeDir': 't:\\\\dalon\\\\misc\\\\paraschut'}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "jobinfo = psu.get_job_template(SetID=True)\n",
    "jobinfo['name'] = ['paraschut example']\n",
    "jobinfo['CodeDir'] = os.path.abspath('.')\n",
    "jobinfo['JobIndex'] = 0\n",
    "jobinfo['script'] = 'python example/job.py {BatchID} {JobIndex}'\n",
    "jobinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's add some random data for the job to operate on. this job will just output its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'example//20210220122655/data_0.pkl'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "data = randint(1, 100, (1, 10**4))\n",
    "psu.generate_data(jobinfo, data)\n",
    "jobinfo['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'python example/job.py 20210220122655 0'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "psu.generate_script(jobinfo)\n",
    "jobinfo['script']"
   ]
  },
  {
   "source": [
    "you may also try setting the 'script' field to 'example/template.sh' and try generating a script. watch the script file that is written in this case.\n",
    "\n",
    "finally, let's add the job we built to the queue."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "psu.add_job_to_queue(jobinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's check that a new job (with JobIndex=0) was added to our queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n20210220122655: paraschut example\n{'init': [0]}\n\nmissing jobs: {}\n\ntotal jobs on server queue: 0\nrunning/complete/total: 0/0/1\n"
     ]
    }
   ],
   "source": [
    "psu.get_queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE, that the server queue job counter (appearing in the last line of `get_queue` output) counts all currently online jobs associated with one's user (including those that are not part of the projects currently managed using `paraschut`).\n",
    "\n",
    "next, let's verify that the metadata has been properly stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'BatchID': 20210220122655,\n",
       " 'JobIndex': 0,\n",
       " 'priority': 1,\n",
       " 'name': ['paraschut example'],\n",
       " 'data_type': 'foo',\n",
       " 'data': 'example//20210220122655/data_0.pkl',\n",
       " 'script': 'python example/job.py 20210220122655 0',\n",
       " 'queue': 'tamir-nano4',\n",
       " 'resources': {'mem': '1gb',\n",
       "  'pmem': '1gb',\n",
       "  'vmem': '3gb',\n",
       "  'pvmem': '3gb',\n",
       "  'cput': '04:59:00'},\n",
       " 'state': 'init',\n",
       " 'CodeDir': 't:\\\\dalon\\\\misc\\\\paraschut',\n",
       " 'md5': 'a5abaab4190f1dd7fab0e540322194c5'}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "psu.get_job_info(20210220122655, 0)"
   ]
  },
  {
   "source": [
    "## multiple jobs and collection\n",
    "\n",
    "first, we'll add 3 more simlar jobs similar to our first job."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_job(jobinfo, i):\n",
    "    newjob = jobinfo.copy()  # duplicating to keep BatchID and similar fields identical\n",
    "    newjob['script'] = 'python example/job.py {BatchID} {JobIndex}'\n",
    "    newjob['JobIndex'] = i\n",
    "\n",
    "    data = randint(1, 100, (1, 10**4))\n",
    "    psu.generate_data(newjob, data)\n",
    "\n",
    "    psu.add_job_to_queue(newjob, build_script=True)\n",
    "    # this will also generate the script\n",
    "\n",
    "for i in range(3):\n",
    "    duplicate_job(jobinfo, i+1)"
   ]
  },
  {
   "source": [
    "let's verify that we indeed generated additional jobs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n20210220122655: paraschut example\n{'init': [0, 1, 2, 3]}\n\nmissing jobs: {}\n\ntotal jobs on server queue: 0\nrunning/complete/total: 0/0/4\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'BatchID': 20210220122655,\n",
       " 'JobIndex': 3,\n",
       " 'priority': 1,\n",
       " 'name': ['paraschut example'],\n",
       " 'data_type': 'foo',\n",
       " 'data': 'example//20210220122655/data_3.pkl',\n",
       " 'script': 'python example/job.py 20210220122655 3',\n",
       " 'queue': 'tamir-nano4',\n",
       " 'resources': {'mem': '1gb',\n",
       "  'pmem': '1gb',\n",
       "  'vmem': '3gb',\n",
       "  'pvmem': '3gb',\n",
       "  'cput': '04:59:00'},\n",
       " 'state': 'init',\n",
       " 'CodeDir': 't:\\\\dalon\\\\misc\\\\paraschut',\n",
       " 'md5': '5477cbf6983e33c5ad1e907231bab119'}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "psu.get_queue()\n",
    "psu.get_job_info(20210220122655, 3)"
   ]
  },
  {
   "source": [
    "finally, let's add a collect job that will compute the mean of means. this job will execute only once the first 4 jobs have completed successfully."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newjob = jobinfo.copy()\n",
    "newjob['priority'] = 0.5  # lower priority gets executed after higher priority jobs are done\n",
    "newjob['script'] = 'python example/collect_job.py {BatchID} {JobIndex}'\n",
    "newjob['JobIndex'] = 4\n",
    "newjob['data'] = range(4)  # pointing to previous JobIndices to compute the mean of their results\n",
    "\n",
    "psu.add_job_to_queue(newjob, build_script=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'BatchID': 20210220122655,\n",
       " 'JobIndex': 4,\n",
       " 'priority': 0.5,\n",
       " 'name': ['paraschut example'],\n",
       " 'data_type': 'foo',\n",
       " 'data': range(0, 4),\n",
       " 'script': 'python example/collect_job.py 20210220122655 4',\n",
       " 'queue': 'tamir-nano4',\n",
       " 'resources': {'mem': '1gb',\n",
       "  'pmem': '1gb',\n",
       "  'vmem': '3gb',\n",
       "  'pvmem': '3gb',\n",
       "  'cput': '04:59:00'},\n",
       " 'state': 'init',\n",
       " 'CodeDir': 't:\\\\dalon\\\\misc\\\\paraschut',\n",
       " 'md5': 'a6e406c9267820d9509a35902eaee20f'}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "psu.get_job_info(20210220122655, 4)"
   ]
  },
  {
   "source": [
    "## submit jobs\n",
    "the only job control function that must run on a server. in our case LocalJobExecutor is configured to run on the local machine."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "submiting:\tpython example/job.py 20210220122655 0\n",
      "submiting:\tpython example/job.py 20210220122655 1\n",
      "submiting:\tpython example/job.py 20210220122655 2\n",
      "submiting:\tpython example/job.py 20210220122655 3\n",
      "max jobs: 1000\n",
      "in queue: 0\n",
      "submitted: 4\n"
     ]
    }
   ],
   "source": [
    "psu.submit_jobs()"
   ]
  },
  {
   "source": [
    "note that only the first 4 jobs were submitted and are currently running. the collect job is waiting for them to complete."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monitor jobs\n",
    "\n",
    "\n",
    "let's check if the job is indeed online and running: (note the * next to jobs 0-3 in the batch, which indicates that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n20210220122655: paraschut example\n{'run': ['0*', '1*', '2*', '3*'], 'init': [4]}\n\nmissing jobs: {}\n\ntotal jobs on server queue: 4\nrunning/complete/total: 4/0/5\n"
     ]
    }
   ],
   "source": [
    "psu.get_queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is how the output looks once the jobs have finished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n20210220122655: paraschut example\n{'complete': [0, 1, 2, 3], 'init': [4]}\n\nmissing jobs: {}\n\ntotal jobs on server queue: 0\nrunning/complete/total: 0/4/5\n"
     ]
    }
   ],
   "source": [
    "psu.get_queue()"
   ]
  },
  {
   "source": [
    "it's time to run the collect job."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "submiting:\tpython example/collect_job.py 20210220122655 4\nmax jobs: 1000\nin queue: 0\nsubmitted: 1\n"
     ]
    }
   ],
   "source": [
    "psu.submit_jobs()"
   ]
  },
  {
   "source": [
    "after a short while all jobs should be in 'complete' state."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n20210220122655: paraschut example\n{'complete': [0, 1, 2, 3, 4]}\n\nmissing jobs: {}\n\ntotal jobs on server queue: 0\nrunning/complete/total: 0/5/5\n"
     ]
    }
   ],
   "source": [
    "psu.get_queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now check the logs created by the jobs (stdout and sterr), and its post-run metadata (which may includs a PBS report summary, for example). in this case, the result was printed to screen in the stdout file as well as stored in the 'result' field of the job metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n[[[stdout log for 20210220122655/paraschut example/job_4:]]]\n\n50.058975000000004\nmax jobs: 1000\nin queue: 0\nsubmitted: 0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'BatchID': 20210220122655,\n",
       " 'JobIndex': 4,\n",
       " 'priority': 0.5,\n",
       " 'name': ['paraschut example'],\n",
       " 'data_type': 'foo',\n",
       " 'data': range(0, 4),\n",
       " 'script': 'python example/collect_job.py 20210220122655 4',\n",
       " 'queue': 'tamir-nano4',\n",
       " 'resources': {'mem': '1gb',\n",
       "  'pmem': '1gb',\n",
       "  'vmem': '3gb',\n",
       "  'pvmem': '3gb',\n",
       "  'cput': '04:59:00'},\n",
       " 'state': 'complete',\n",
       " 'CodeDir': 't:\\\\dalon\\\\misc\\\\paraschut',\n",
       " 'subtime': 20210220122847,\n",
       " 'stdout': ['example/20210220122655/logs/3816927923.power8.tau.ac.il.OU'],\n",
       " 'stderr': ['example/20210220122655/logs/3816927923.power8.tau.ac.il.ER'],\n",
       " 'hostname': 'alond-pc',\n",
       " 'result': 50.058975000000004,\n",
       " 'qstat': {},\n",
       " 'md5': 'e3ca8880b8b6d0047aeca777415e7045'}"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "psu.print_log(20210220122655, 4, 'stdout')\n",
    "psu.get_job_info(20210220122655, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, we may clear all batches that have completed all their jobs using the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nmissing jobs: {}\n\ntotal jobs on server queue: 0\nrunning/complete/total: 0/0/0\n"
     ]
    }
   ],
   "source": [
    "psu.remove_batch_by_state('complete')\n",
    "psu.get_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}